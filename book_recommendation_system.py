# -*- coding: utf-8 -*-
"""book_recommendation_system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CpjV4eFf0lq2OuGoqgraxyEC1YTpRQiJ

# **Load Dataset**

Membuat direktori .kaggle untuk menyimpan file API key dari Kaggle.
"""

!mkdir -p ~/.kaggle

"""Mengunggah file API key dari lokal ke Colab."""

from google.colab import files
files.upload()

"""Mengunduh dataset Bookcrossing dari Kaggle menggunakan API key yang telah diunggah"""

!kaggle datasets download -d ruchi798/bookcrossing-dataset

"""Mengekstrak file dataset Bookcrossing yang telah diunduh dari file ZIP."""

!unzip bookcrossing-dataset.zip

"""Memasang library annoy untuk pencarian approximate nearest neighbors dan fuzzywuzzy untuk pencocokan teks berbasis string."""

!pip install annoy
!pip install fuzzywuzzy[speedup]

"""# **Preprocessing Data**

Mengimpor library yang dibutuhkan untuk pemrosesan data, ekstraksi fitur teks dengan TF-IDF, pencarian nearest neighbors, pencocokan teks menggunakan fuzzy matching, pembagian dataset, evaluasi metrik, dan pengurangan dimensi menggunakan TruncatedSVD.
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors
from fuzzywuzzy import process
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.decomposition import TruncatedSVD

"""Membaca file CSV yang berisi data buku, penilaian, dan pengguna dari folder 'Book reviews' dengan memisahkan kolom menggunakan delimiter ;, menangani kesalahan baris dengan parameter on_bad_lines='skip', dan menggunakan encoding latin-1 untuk mengatasi karakter khusus."""

books = pd.read_csv('/content/Book reviews/Book reviews/BX_Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip')
ratings = pd.read_csv('/content/Book reviews/Book reviews/BX-Book-Ratings.csv', sep=';', encoding='latin-1', on_bad_lines='skip')
users = pd.read_csv('/content/Book reviews/Book reviews/BX-Users.csv', sep=';', encoding='latin-1', on_bad_lines='skip')

"""Menampilkan lima baris pertama dari masing-masing dataset: buku, penilaian, dan pengguna, untuk memeriksa isi dan struktur data."""

print("Books Dataset:")
print(books.head())

print("\nRatings Dataset:")
print(ratings.head())

print("\nUsers Dataset:")
print(users.head())

"""Menampilkan informasi detail tentang dataset buku, penilaian, dan pengguna, termasuk jumlah entri, tipe data di setiap kolom, dan apakah ada nilai yang hilang."""

print("\nBooks Dataset Info:")
print(books.info())

print("\nRatings Dataset Info:")
print(ratings.info())

print("\nUsers Dataset Info:")
print(users.info())

"""Memeriksa jumlah nilai yang hilang pada setiap kolom dataset buku, menghitung jumlah ISBN unik (buku unik), dan menampilkan statistik deskriptif untuk kolom 'Year-Of-Publication'."""

print("Books Dataset - Checking for missing values:")
print(books.isnull().sum())

print("\nUnique Books:")
print(books['ISBN'].nunique())

print("\nBooks Dataset - Descriptive statistics for Year-Of-Publication:")
print(books['Year-Of-Publication'].describe())

"""Memeriksa nilai yang hilang dalam dataset penilaian, serta menghitung jumlah pengguna dan buku unik yang terdapat dalam dataset tersebut."""

print("Ratings Dataset - Checking for missing values:")
print(ratings.isnull().sum())

print("\nUnique Users and Books in Ratings:")
print(f"Unique Users: {ratings['User-ID'].nunique()}")
print(f"Unique Books: {ratings['ISBN'].nunique()}")

"""Memeriksa jumlah nilai yang hilang pada dataset pengguna dan menampilkan statistik deskriptif untuk kolom 'Age'."""

print("\nUsers Dataset - Checking for missing values:")
print(users.isnull().sum())

print("\nUsers Dataset - Descriptive statistics for Age:")
print(users['Age'].describe())

"""Membersihkan dataset dengan cara menghapus baris yang memiliki nilai kosong pada kolom penting (ISBN, judul buku, pengarang, tahun terbit, dan penerbit), menghapus duplikat berdasarkan ISBN, serta memfilter pengguna dengan usia antara 5 dan 100 tahun."""

books_clean = books.dropna(subset=['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher'])
ratings_clean = ratings.dropna()
users_clean = users.dropna(subset=['User-ID', 'Age'])

books_clean = books_clean.drop_duplicates(subset='ISBN')

users_clean = users_clean[(users_clean['Age'] >= 5) & (users_clean['Age'] <= 100)]

"""# **Feature Engineering**

Membuat fitur gabungan pada dataset buku dengan menggabungkan judul buku, pengarang, dan penerbit ke dalam satu kolom yang disebut 'combined_features', lalu menampilkan lima baris pertama dari kolom tersebut.
"""

books_clean['combined_features'] = books_clean['Book-Title'] + ' ' + books_clean['Book-Author'] + ' ' + books_clean['Publisher']

print(books_clean['combined_features'].head())

"""Menggunakan TF-IDF Vectorizer untuk mengubah fitur gabungan ('combined_features') menjadi representasi numerik, menghilangkan kata-kata umum (stop words) dalam bahasa Inggris, dan menampilkan ukuran matriks TF-IDF yang dihasilkan."""

tfidf = TfidfVectorizer(stop_words='english')

tfidf_matrix = tfidf.fit_transform(books_clean['combined_features'])

print(f"Ukuran TF-IDF Matrix: {tfidf_matrix.shape}")

"""Membangun model Nearest Neighbors menggunakan metrik cosine similarity dan algoritma brute-force untuk menemukan buku-buku yang mirip berdasarkan fitur TF-IDF yang telah diekstraksi."""

model_nn = NearestNeighbors(metric='cosine', algorithm='brute')
model_nn.fit(tfidf_matrix)

"""Mendefinisikan fungsi untuk mendapatkan rekomendasi buku menggunakan model Nearest Neighbors. Fungsi ini mencari buku yang mirip dengan buku yang diberikan berdasarkan fitur TF-IDF. Jika buku tidak ditemukan, pesan kesalahan ditampilkan. Menampilkan hasil rekomendasi untuk buku 'Harry Potter and the Sorcerer's Stone'."""

indices = pd.Series(books_clean.index, index=books_clean['Book-Title']).drop_duplicates()

def get_nn_recommendations(title, n_recommendations=10):
    if title not in indices:
        return "Buku tidak ditemukan."

    idx = indices[title]

    distances, indices_nn = model_nn.kneighbors(tfidf_matrix[idx], n_neighbors=n_recommendations + 1)

    recommended_indices = indices_nn[0][1:]

    return books_clean['Book-Title'].iloc[recommended_indices]

print(get_nn_recommendations('Harry Potter and the Sorcerer\'s Stone'))

"""Menghapus nilai kosong dalam dataset penilaian, lalu menggabungkan dataset penilaian yang bersih dengan dataset buku yang bersih berdasarkan kolom ISBN. Menampilkan lima baris pertama dari hasil penggabungan."""

ratings_clean = ratings.dropna()
ratings_books = pd.merge(ratings_clean, books_clean, on='ISBN')

print(ratings_books.head())

"""# **Building Recommendation System**

Mendefinisikan fungsi fuzzy_match yang menggunakan fuzzy string matching untuk menemukan judul buku yang paling mirip dengan judul yang diberikan. Fungsi ini akan mengembalikan sejumlah judul yang paling cocok berdasarkan batas yang ditentukan.
"""

def fuzzy_match(title, books, limit=3):
    matches = process.extract(title, books, limit=limit)
    return matches

"""Mendefinisikan fungsi get_fuzzy_nn_recommendations yang pertama kali mencari judul buku terdekat menggunakan fuzzy matching. Setelah judul yang paling cocok ditemukan, fungsi ini menggunakan model Nearest Neighbors untuk memberikan rekomendasi buku berdasarkan judul tersebut. Jika tidak ada judul yang cocok ditemukan, fungsi akan menampilkan pesan kesalahan."""

def get_fuzzy_nn_recommendations(title, n_recommendations=10):
    matches = fuzzy_match(title, books_clean['Book-Title'].values)

    if not matches:
        return "Tidak ada judul yang cocok ditemukan."

    matched_title = matches[0][0]

    print(f"Menampilkan rekomendasi untuk: '{matched_title}'")

    idx = indices[matched_title]

    distances, indices_nn = model_nn.kneighbors(tfidf_matrix[idx], n_neighbors=n_recommendations + 1)

    recommended_indices = indices_nn[0][1:]

    return books_clean['Book-Title'].iloc[recommended_indices]

"""Mendefinisikan fungsi recommend_for_user yang memberikan rekomendasi buku untuk pengguna berdasarkan buku yang telah diberi rating tertinggi oleh pengguna tersebut. Fungsi ini mengambil beberapa buku yang diberi rating tertinggi oleh pengguna, menggunakan model Nearest Neighbors untuk memberikan rekomendasi, lalu menghilangkan duplikasi dari daftar rekomendasi akhir."""

def recommend_for_user(user_id, ratings_books, n_recommendations=10):
    user_ratings = ratings_books[ratings_books['User-ID'] == user_id]

    if user_ratings.empty:
        return "Pengguna tidak ditemukan atau belum memberikan rating."

    top_rated_books = user_ratings.sort_values(by='Book-Rating', ascending=False).head(5)

    recommended_books = []
    for book in top_rated_books['Book-Title'].values:
        recommended_books.extend(get_nn_recommendations(book, n_recommendations))

    recommended_books = list(dict.fromkeys(recommended_books))

    return recommended_books[:n_recommendations]

"""Mendefinisikan fungsi interactive_recommendation untuk menjalankan rekomendasi secara interaktif. Jika input berupa ID pengguna (digit), rekomendasi diberikan berdasarkan preferensi pengguna tersebut. Jika input berupa judul buku (teks), rekomendasi diberikan berdasarkan judul buku dengan bantuan fuzzy matching. Fungsi ini dijalankan dua kali untuk menguji interaktivitas."""

def interactive_recommendation():
    user_input = input("Masukkan judul buku atau ID pengguna: ")

    if user_input.isdigit():
        user_id = int(user_input)
        print(f"Rekomendasi untuk pengguna {user_id}:")
        print(recommend_for_user(user_id, ratings_books))
    else:
        print(f"Rekomendasi untuk buku '{user_input}':")
        print(get_fuzzy_nn_recommendations(user_input))

interactive_recommendation()
interactive_recommendation()

"""# **Evaluation**

Membagi dataset penilaian menjadi data latih (80%) dan data uji (20%) menggunakan train_test_split. Menampilkan ukuran data latih dan data uji untuk memverifikasi pembagian.
"""

train_data, test_data = train_test_split(ratings_clean, test_size=0.2, random_state=42)

print(f"Train data size: {train_data.shape}")
print(f"Test data size: {test_data.shape}")

"""Mendefinisikan fungsi evaluate_recommendations untuk mengevaluasi rekomendasi yang diberikan kepada seorang pengguna berdasarkan precision, recall, dan F1-score. Fungsi ini memeriksa buku yang diberi rating tinggi (>= 8) oleh pengguna sebagai 'true positives', lalu membandingkannya dengan buku yang direkomendasikan. Metrik precision, recall, dan F1 dihitung untuk menilai akurasi rekomendasi."""

def evaluate_recommendations(user_id, model_nn, n_recommendations=10):
    user_test_ratings = test_data[test_data['User-ID'] == user_id]

    if user_test_ratings.empty:
        return None

    true_positive_books = user_test_ratings[user_test_ratings['Book-Rating'] >= 8]['ISBN'].values

    recommended_books = recommend_for_user(user_id, ratings_books, n_recommendations)

    if not recommended_books:
        return None

    if isinstance(recommended_books, str):
        recommended_books = [recommended_books]

    recommended_books_isbn = books_clean[books_clean['Book-Title'].isin(recommended_books)]['ISBN'].values

    y_true = [1 if isbn in true_positive_books else 0 for isbn in recommended_books_isbn]
    y_pred = [1] * len(recommended_books_isbn)

    precision = precision_score(y_true, y_pred, zero_division=1)
    recall = recall_score(y_true, y_pred, zero_division=1)
    f1 = f1_score(y_true, y_pred, zero_division=1)

    return precision, recall, f1

"""Mendefinisikan fungsi evaluate_for_sampled_users_in_batch yang mengevaluasi rekomendasi untuk sekelompok pengguna secara batch. Fungsi ini menghitung precision, recall, dan F1-score rata-rata untuk pengguna yang diambil secara acak dari data uji. Evaluasi dilakukan secara batch untuk efisiensi. Hasil akhirnya adalah precision, recall, dan F1-score rata-rata untuk semua pengguna yang diuji."""

sampled_user_ids = np.random.choice(test_data['User-ID'].unique(), size=int(0.1 * len(test_data['User-ID'].unique())), replace=False)

def evaluate_for_sampled_users_in_batch(test_data, model_nn, sampled_user_ids, batch_size=100, n_recommendations=10):
    precisions = []
    recalls = []
    f1_scores = []

    for i in range(0, len(sampled_user_ids), batch_size):
        batch_user_ids = sampled_user_ids[i:i + batch_size]
        for user_id in batch_user_ids:
            result = evaluate_recommendations(user_id, model_nn, n_recommendations)
            if result:
                precision, recall, f1 = result
                precisions.append(precision)
                recalls.append(recall)
                f1_scores.append(f1)

    avg_precision = sum(precisions) / len(precisions) if precisions else 0
    avg_recall = sum(recalls) / len(recalls) if recalls else 0
    avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0

    return avg_precision, avg_recall, avg_f1

avg_precision, avg_recall, avg_f1 = evaluate_for_sampled_users_in_batch(test_data, model_nn, sampled_user_ids, batch_size=100)

print(f"Rata-rata Precision: {avg_precision}")
print(f"Rata-rata Recall: {avg_recall}")
print(f"Rata-rata F1-score: {avg_f1}")