{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Dataset**"
      ],
      "metadata": {
        "id": "ItYhbcoI7qT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat direktori .kaggle untuk menyimpan file API key dari Kaggle."
      ],
      "metadata": {
        "id": "yeLVovEH4tcn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8lOt-ppuyoLn"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengunggah file API key dari lokal ke Colab."
      ],
      "metadata": {
        "id": "bu6qsdSG4urj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "sHAVtTh9V-PN",
        "outputId": "e1cc6af4-9ae3-4412-b5c5-cdecafe3af3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4c3c4baa-a422-4f30-b269-c09d8e560be4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4c3c4baa-a422-4f30-b269-c09d8e560be4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"irgisetiawan\",\"key\":\"bc41477d4b375913aa3fc1ee0c2e697f\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengunduh dataset Bookcrossing dari Kaggle menggunakan API key yang telah diunggah"
      ],
      "metadata": {
        "id": "ySTiex3k4yY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ruchi798/bookcrossing-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_zK96BAWJvI",
        "outputId": "5e8a3ff2-7809-4f80-fb23-acc9596ab4c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ruchi798/bookcrossing-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading bookcrossing-dataset.zip to /content\n",
            " 99% 75.0M/76.1M [00:01<00:00, 65.2MB/s]\n",
            "100% 76.1M/76.1M [00:01<00:00, 65.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengekstrak file dataset Bookcrossing yang telah diunduh dari file ZIP."
      ],
      "metadata": {
        "id": "2VUO9Q6q5TYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip bookcrossing-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwXYBWGqWhsW",
        "outputId": "76cdbc57-250a-45e2-c524-9a17352d1d97"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  bookcrossing-dataset.zip\n",
            "  inflating: Book reviews/Book reviews/BX-Book-Ratings.csv  \n",
            "  inflating: Book reviews/Book reviews/BX-Users.csv  \n",
            "  inflating: Book reviews/Book reviews/BX_Books.csv  \n",
            "  inflating: Books Data with Category Language and Summary/Preprocessed_data.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memasang library annoy untuk pencarian approximate nearest neighbors dan fuzzywuzzy untuk pencocokan teks berbasis string."
      ],
      "metadata": {
        "id": "gu8LX2OX5UOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy\n",
        "!pip install fuzzywuzzy[speedup]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USQCA6Oskhbq",
        "outputId": "04e43db7-c7a0-4097-862f-c3cd9b399f42"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp310-cp310-linux_x86_64.whl size=552446 sha256=9e2b8e71c7c4c89f39f86e0e904fe5c7f4b5a0f9e9ba509b465beff1a0b71a40\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/8a/da/f714bcf46c5efdcfcac0559e63370c21abe961c48e3992465a\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.3\n",
            "Collecting fuzzywuzzy[speedup]\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-levenshtein>=0.12 (from fuzzywuzzy[speedup])\n",
            "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.25.1 (from python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
            "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
            "  Downloading rapidfuzz-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading rapidfuzz-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, rapidfuzz, Levenshtein, python-levenshtein\n",
            "Successfully installed Levenshtein-0.25.1 fuzzywuzzy-0.18.0 python-levenshtein-0.25.1 rapidfuzz-3.9.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing Data**"
      ],
      "metadata": {
        "id": "ukE6i3iB7iwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengimpor library yang dibutuhkan untuk pemrosesan data, ekstraksi fitur teks dengan TF-IDF, pencarian nearest neighbors, pencocokan teks menggunakan fuzzy matching, pembagian dataset, evaluasi metrik, dan pengurangan dimensi menggunakan TruncatedSVD."
      ],
      "metadata": {
        "id": "gUt3-mm25YzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from fuzzywuzzy import process\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.decomposition import TruncatedSVD"
      ],
      "metadata": {
        "id": "-RTmqjs-WozJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membaca file CSV yang berisi data buku, penilaian, dan pengguna dari folder 'Book reviews' dengan memisahkan kolom menggunakan delimiter ;, menangani kesalahan baris dengan parameter on_bad_lines='skip', dan menggunakan encoding latin-1 untuk mengatasi karakter khusus."
      ],
      "metadata": {
        "id": "O1gnpXKa5gos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books = pd.read_csv('/content/Book reviews/Book reviews/BX_Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n",
        "ratings = pd.read_csv('/content/Book reviews/Book reviews/BX-Book-Ratings.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n",
        "users = pd.read_csv('/content/Book reviews/Book reviews/BX-Users.csv', sep=';', encoding='latin-1', on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "DkNWOWH_bHKf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan lima baris pertama dari masing-masing dataset: buku, penilaian, dan pengguna, untuk memeriksa isi dan struktur data."
      ],
      "metadata": {
        "id": "76-Mt5QJ5m0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Books Dataset:\")\n",
        "print(books.head())\n",
        "\n",
        "print(\"\\nRatings Dataset:\")\n",
        "print(ratings.head())\n",
        "\n",
        "print(\"\\nUsers Dataset:\")\n",
        "print(users.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkYAkNQabLNE",
        "outputId": "03771091-388a-4c4d-8550-d64362b5e5a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books Dataset:\n",
            "         ISBN                                         Book-Title  \\\n",
            "0  0195153448                                Classical Mythology   \n",
            "1  0002005018                                       Clara Callan   \n",
            "2  0060973129                               Decision in Normandy   \n",
            "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
            "4  0393045218                             The Mummies of Urumchi   \n",
            "\n",
            "            Book-Author  Year-Of-Publication                Publisher  \\\n",
            "0    Mark P. O. Morford                 2002  Oxford University Press   \n",
            "1  Richard Bruce Wright                 2001    HarperFlamingo Canada   \n",
            "2          Carlo D'Este                 1991          HarperPerennial   \n",
            "3      Gina Bari Kolata                 1999     Farrar Straus Giroux   \n",
            "4       E. J. W. Barber                 1999   W. W. Norton & Company   \n",
            "\n",
            "                                         Image-URL-S  \\\n",
            "0  http://images.amazon.com/images/P/0195153448.0...   \n",
            "1  http://images.amazon.com/images/P/0002005018.0...   \n",
            "2  http://images.amazon.com/images/P/0060973129.0...   \n",
            "3  http://images.amazon.com/images/P/0374157065.0...   \n",
            "4  http://images.amazon.com/images/P/0393045218.0...   \n",
            "\n",
            "                                         Image-URL-M  \\\n",
            "0  http://images.amazon.com/images/P/0195153448.0...   \n",
            "1  http://images.amazon.com/images/P/0002005018.0...   \n",
            "2  http://images.amazon.com/images/P/0060973129.0...   \n",
            "3  http://images.amazon.com/images/P/0374157065.0...   \n",
            "4  http://images.amazon.com/images/P/0393045218.0...   \n",
            "\n",
            "                                         Image-URL-L  \n",
            "0  http://images.amazon.com/images/P/0195153448.0...  \n",
            "1  http://images.amazon.com/images/P/0002005018.0...  \n",
            "2  http://images.amazon.com/images/P/0060973129.0...  \n",
            "3  http://images.amazon.com/images/P/0374157065.0...  \n",
            "4  http://images.amazon.com/images/P/0393045218.0...  \n",
            "\n",
            "Ratings Dataset:\n",
            "   User-ID        ISBN  Book-Rating\n",
            "0   276725  034545104X            0\n",
            "1   276726  0155061224            5\n",
            "2   276727  0446520802            0\n",
            "3   276729  052165615X            3\n",
            "4   276729  0521795028            6\n",
            "\n",
            "Users Dataset:\n",
            "   User-ID                            Location   Age\n",
            "0        1                  nyc, new york, usa   NaN\n",
            "1        2           stockton, california, usa  18.0\n",
            "2        3     moscow, yukon territory, russia   NaN\n",
            "3        4           porto, v.n.gaia, portugal  17.0\n",
            "4        5  farnborough, hants, united kingdom   NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan informasi detail tentang dataset buku, penilaian, dan pengguna, termasuk jumlah entri, tipe data di setiap kolom, dan apakah ada nilai yang hilang."
      ],
      "metadata": {
        "id": "uWvtAytO5xZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBooks Dataset Info:\")\n",
        "print(books.info())\n",
        "\n",
        "print(\"\\nRatings Dataset Info:\")\n",
        "print(ratings.info())\n",
        "\n",
        "print(\"\\nUsers Dataset Info:\")\n",
        "print(users.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCI9l3FybMMn",
        "outputId": "279f1463-3eb1-4d59-d8ff-48bb0e9863ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Books Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 271379 entries, 0 to 271378\n",
            "Data columns (total 8 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   ISBN                 271379 non-null  object\n",
            " 1   Book-Title           271379 non-null  object\n",
            " 2   Book-Author          271377 non-null  object\n",
            " 3   Year-Of-Publication  271379 non-null  int64 \n",
            " 4   Publisher            271377 non-null  object\n",
            " 5   Image-URL-S          271379 non-null  object\n",
            " 6   Image-URL-M          271379 non-null  object\n",
            " 7   Image-URL-L          271379 non-null  object\n",
            "dtypes: int64(1), object(7)\n",
            "memory usage: 16.6+ MB\n",
            "None\n",
            "\n",
            "Ratings Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1149780 entries, 0 to 1149779\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count    Dtype \n",
            "---  ------       --------------    ----- \n",
            " 0   User-ID      1149780 non-null  int64 \n",
            " 1   ISBN         1149780 non-null  object\n",
            " 2   Book-Rating  1149780 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 26.3+ MB\n",
            "None\n",
            "\n",
            "Users Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 278858 entries, 0 to 278857\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count   Dtype  \n",
            "---  ------    --------------   -----  \n",
            " 0   User-ID   278858 non-null  int64  \n",
            " 1   Location  278858 non-null  object \n",
            " 2   Age       168096 non-null  float64\n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 6.4+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memeriksa jumlah nilai yang hilang pada setiap kolom dataset buku, menghitung jumlah ISBN unik (buku unik), dan menampilkan statistik deskriptif untuk kolom 'Year-Of-Publication'."
      ],
      "metadata": {
        "id": "GcND1kJ_5-MA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Books Dataset - Checking for missing values:\")\n",
        "print(books.isnull().sum())\n",
        "\n",
        "print(\"\\nUnique Books:\")\n",
        "print(books['ISBN'].nunique())\n",
        "\n",
        "print(\"\\nBooks Dataset - Descriptive statistics for Year-Of-Publication:\")\n",
        "print(books['Year-Of-Publication'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCuY6fq0cfot",
        "outputId": "0f522aaf-8852-432d-87c3-94addb7a0dd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books Dataset - Checking for missing values:\n",
            "ISBN                   0\n",
            "Book-Title             0\n",
            "Book-Author            2\n",
            "Year-Of-Publication    0\n",
            "Publisher              2\n",
            "Image-URL-S            0\n",
            "Image-URL-M            0\n",
            "Image-URL-L            0\n",
            "dtype: int64\n",
            "\n",
            "Unique Books:\n",
            "271379\n",
            "\n",
            "Books Dataset - Descriptive statistics for Year-Of-Publication:\n",
            "count    271379.000000\n",
            "mean       1959.756050\n",
            "std         258.011363\n",
            "min           0.000000\n",
            "25%        1989.000000\n",
            "50%        1995.000000\n",
            "75%        2000.000000\n",
            "max        2050.000000\n",
            "Name: Year-Of-Publication, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memeriksa nilai yang hilang dalam dataset penilaian, serta menghitung jumlah pengguna dan buku unik yang terdapat dalam dataset tersebut."
      ],
      "metadata": {
        "id": "vn9HGlc46E7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ratings Dataset - Checking for missing values:\")\n",
        "print(ratings.isnull().sum())\n",
        "\n",
        "print(\"\\nUnique Users and Books in Ratings:\")\n",
        "print(f\"Unique Users: {ratings['User-ID'].nunique()}\")\n",
        "print(f\"Unique Books: {ratings['ISBN'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHmyS8pAfsiB",
        "outputId": "90f570fc-5d43-43e1-eff9-bca20ab0f396"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings Dataset - Checking for missing values:\n",
            "User-ID        0\n",
            "ISBN           0\n",
            "Book-Rating    0\n",
            "dtype: int64\n",
            "\n",
            "Unique Users and Books in Ratings:\n",
            "Unique Users: 105283\n",
            "Unique Books: 340556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memeriksa jumlah nilai yang hilang pada dataset pengguna dan menampilkan statistik deskriptif untuk kolom 'Age'."
      ],
      "metadata": {
        "id": "j30ctmKe6Ikd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nUsers Dataset - Checking for missing values:\")\n",
        "print(users.isnull().sum())\n",
        "\n",
        "print(\"\\nUsers Dataset - Descriptive statistics for Age:\")\n",
        "print(users['Age'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER8sI80Rfxf4",
        "outputId": "3ddc5c0d-d8b0-4a0e-a988-9bd30831f139"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Users Dataset - Checking for missing values:\n",
            "User-ID          0\n",
            "Location         0\n",
            "Age         110762\n",
            "dtype: int64\n",
            "\n",
            "Users Dataset - Descriptive statistics for Age:\n",
            "count    168096.000000\n",
            "mean         34.751434\n",
            "std          14.428097\n",
            "min           0.000000\n",
            "25%          24.000000\n",
            "50%          32.000000\n",
            "75%          44.000000\n",
            "max         244.000000\n",
            "Name: Age, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membersihkan dataset dengan cara menghapus baris yang memiliki nilai kosong pada kolom penting (ISBN, judul buku, pengarang, tahun terbit, dan penerbit), menghapus duplikat berdasarkan ISBN, serta memfilter pengguna dengan usia antara 5 dan 100 tahun."
      ],
      "metadata": {
        "id": "rJtWA0rP6MmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_clean = books.dropna(subset=['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher'])\n",
        "ratings_clean = ratings.dropna()\n",
        "users_clean = users.dropna(subset=['User-ID', 'Age'])\n",
        "\n",
        "books_clean = books_clean.drop_duplicates(subset='ISBN')\n",
        "\n",
        "users_clean = users_clean[(users_clean['Age'] >= 5) & (users_clean['Age'] <= 100)]"
      ],
      "metadata": {
        "id": "Qknf2-Pef-v-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "jaPjQNC68X2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat fitur gabungan pada dataset buku dengan menggabungkan judul buku, pengarang, dan penerbit ke dalam satu kolom yang disebut 'combined_features', lalu menampilkan lima baris pertama dari kolom tersebut."
      ],
      "metadata": {
        "id": "0dIs1-w96S0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_clean['combined_features'] = books_clean['Book-Title'] + ' ' + books_clean['Book-Author'] + ' ' + books_clean['Publisher']\n",
        "\n",
        "print(books_clean['combined_features'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MpQTWIChYvG",
        "outputId": "2b110b2f-ad77-4e01-de8c-0561f0fc33ec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Classical Mythology Mark P. O. Morford Oxford ...\n",
            "1    Clara Callan Richard Bruce Wright HarperFlamin...\n",
            "2    Decision in Normandy Carlo D'Este HarperPerennial\n",
            "3    Flu: The Story of the Great Influenza Pandemic...\n",
            "4    The Mummies of Urumchi E. J. W. Barber W. W. N...\n",
            "Name: combined_features, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menggunakan TF-IDF Vectorizer untuk mengubah fitur gabungan ('combined_features') menjadi representasi numerik, menghilangkan kata-kata umum (stop words) dalam bahasa Inggris, dan menampilkan ukuran matriks TF-IDF yang dihasilkan."
      ],
      "metadata": {
        "id": "qSzVDkRL6a_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "tfidf_matrix = tfidf.fit_transform(books_clean['combined_features'])\n",
        "\n",
        "print(f\"Ukuran TF-IDF Matrix: {tfidf_matrix.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0thGjXAhwcm",
        "outputId": "d9a789b0-8fef-4c55-a901-dd0605bcbec5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ukuran TF-IDF Matrix: (271375, 116788)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membangun model Nearest Neighbors menggunakan metrik cosine similarity dan algoritma brute-force untuk menemukan buku-buku yang mirip berdasarkan fitur TF-IDF yang telah diekstraksi."
      ],
      "metadata": {
        "id": "xk_fKrUU6d35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_nn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "model_nn.fit(tfidf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "QCcSEiGDnguk",
        "outputId": "12064bbf-4f3b-46f4-88be-502a30913cc8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='brute', metric='cosine')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mendefinisikan fungsi untuk mendapatkan rekomendasi buku menggunakan model Nearest Neighbors. Fungsi ini mencari buku yang mirip dengan buku yang diberikan berdasarkan fitur TF-IDF. Jika buku tidak ditemukan, pesan kesalahan ditampilkan. Menampilkan hasil rekomendasi untuk buku 'Harry Potter and the Sorcerer's Stone'."
      ],
      "metadata": {
        "id": "uYVs1J_l6iSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = pd.Series(books_clean.index, index=books_clean['Book-Title']).drop_duplicates()\n",
        "\n",
        "def get_nn_recommendations(title, n_recommendations=10):\n",
        "    if title not in indices:\n",
        "        return \"Buku tidak ditemukan.\"\n",
        "\n",
        "    idx = indices[title]\n",
        "\n",
        "    distances, indices_nn = model_nn.kneighbors(tfidf_matrix[idx], n_neighbors=n_recommendations + 1)\n",
        "\n",
        "    recommended_indices = indices_nn[0][1:]\n",
        "\n",
        "    return books_clean['Book-Title'].iloc[recommended_indices]\n",
        "\n",
        "print(get_nn_recommendations('Harry Potter and the Sorcerer\\'s Stone'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UActLBllKyz",
        "outputId": "4baeb74f-3f4d-42e9-b25d-398a8eda9143"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52724                     An American Killing\n",
            "129304                Love Her Madly: A Novel\n",
            "128062    She's Not There: A Poppy Rice Novel\n",
            "264643                     The Book of Phoebe\n",
            "66324                         Brown-Eyed Girl\n",
            "140398                       Gabriel's Lament\n",
            "208207                       Gabriel's Lament\n",
            "204078                      Way to Go, Smith!\n",
            "83117                       Mary Ann and Bill\n",
            "221632                    Lament a Lost Lover\n",
            "Name: Book-Title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menghapus nilai kosong dalam dataset penilaian, lalu menggabungkan dataset penilaian yang bersih dengan dataset buku yang bersih berdasarkan kolom ISBN. Menampilkan lima baris pertama dari hasil penggabungan."
      ],
      "metadata": {
        "id": "iS9k1WNI6qYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_clean = ratings.dropna()\n",
        "ratings_books = pd.merge(ratings_clean, books_clean, on='ISBN')\n",
        "\n",
        "print(ratings_books.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuro8NDFsG8P",
        "outputId": "2a51638d-6df7-4de2-83ed-71c39b86d5f3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   User-ID        ISBN  Book-Rating            Book-Title Book-Author  \\\n",
            "0   276725  034545104X            0  Flesh Tones: A Novel  M. J. Rose   \n",
            "1     2313  034545104X            5  Flesh Tones: A Novel  M. J. Rose   \n",
            "2     6543  034545104X            0  Flesh Tones: A Novel  M. J. Rose   \n",
            "3     8680  034545104X            5  Flesh Tones: A Novel  M. J. Rose   \n",
            "4    10314  034545104X            9  Flesh Tones: A Novel  M. J. Rose   \n",
            "\n",
            "   Year-Of-Publication         Publisher  \\\n",
            "0                 2002  Ballantine Books   \n",
            "1                 2002  Ballantine Books   \n",
            "2                 2002  Ballantine Books   \n",
            "3                 2002  Ballantine Books   \n",
            "4                 2002  Ballantine Books   \n",
            "\n",
            "                                         Image-URL-S  \\\n",
            "0  http://images.amazon.com/images/P/034545104X.0...   \n",
            "1  http://images.amazon.com/images/P/034545104X.0...   \n",
            "2  http://images.amazon.com/images/P/034545104X.0...   \n",
            "3  http://images.amazon.com/images/P/034545104X.0...   \n",
            "4  http://images.amazon.com/images/P/034545104X.0...   \n",
            "\n",
            "                                         Image-URL-M  \\\n",
            "0  http://images.amazon.com/images/P/034545104X.0...   \n",
            "1  http://images.amazon.com/images/P/034545104X.0...   \n",
            "2  http://images.amazon.com/images/P/034545104X.0...   \n",
            "3  http://images.amazon.com/images/P/034545104X.0...   \n",
            "4  http://images.amazon.com/images/P/034545104X.0...   \n",
            "\n",
            "                                         Image-URL-L  \\\n",
            "0  http://images.amazon.com/images/P/034545104X.0...   \n",
            "1  http://images.amazon.com/images/P/034545104X.0...   \n",
            "2  http://images.amazon.com/images/P/034545104X.0...   \n",
            "3  http://images.amazon.com/images/P/034545104X.0...   \n",
            "4  http://images.amazon.com/images/P/034545104X.0...   \n",
            "\n",
            "                                  combined_features  \n",
            "0  Flesh Tones: A Novel M. J. Rose Ballantine Books  \n",
            "1  Flesh Tones: A Novel M. J. Rose Ballantine Books  \n",
            "2  Flesh Tones: A Novel M. J. Rose Ballantine Books  \n",
            "3  Flesh Tones: A Novel M. J. Rose Ballantine Books  \n",
            "4  Flesh Tones: A Novel M. J. Rose Ballantine Books  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Recommendation System**"
      ],
      "metadata": {
        "id": "IrjWUw0N8ncw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mendefinisikan fungsi fuzzy_match yang menggunakan fuzzy string matching untuk menemukan judul buku yang paling mirip dengan judul yang diberikan. Fungsi ini akan mengembalikan sejumlah judul yang paling cocok berdasarkan batas yang ditentukan."
      ],
      "metadata": {
        "id": "GdPWHgPT6rXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fuzzy_match(title, books, limit=3):\n",
        "    matches = process.extract(title, books, limit=limit)\n",
        "    return matches"
      ],
      "metadata": {
        "id": "HC9VOHH5q08T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mendefinisikan fungsi get_fuzzy_nn_recommendations yang pertama kali mencari judul buku terdekat menggunakan fuzzy matching. Setelah judul yang paling cocok ditemukan, fungsi ini menggunakan model Nearest Neighbors untuk memberikan rekomendasi buku berdasarkan judul tersebut. Jika tidak ada judul yang cocok ditemukan, fungsi akan menampilkan pesan kesalahan."
      ],
      "metadata": {
        "id": "qlSwC9wV6vr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fuzzy_nn_recommendations(title, n_recommendations=10):\n",
        "    matches = fuzzy_match(title, books_clean['Book-Title'].values)\n",
        "\n",
        "    if not matches:\n",
        "        return \"Tidak ada judul yang cocok ditemukan.\"\n",
        "\n",
        "    matched_title = matches[0][0]\n",
        "\n",
        "    print(f\"Menampilkan rekomendasi untuk: '{matched_title}'\")\n",
        "\n",
        "    idx = indices[matched_title]\n",
        "\n",
        "    distances, indices_nn = model_nn.kneighbors(tfidf_matrix[idx], n_neighbors=n_recommendations + 1)\n",
        "\n",
        "    recommended_indices = indices_nn[0][1:]\n",
        "\n",
        "    return books_clean['Book-Title'].iloc[recommended_indices]"
      ],
      "metadata": {
        "id": "_z27v2j_q9Ys"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mendefinisikan fungsi recommend_for_user yang memberikan rekomendasi buku untuk pengguna berdasarkan buku yang telah diberi rating tertinggi oleh pengguna tersebut. Fungsi ini mengambil beberapa buku yang diberi rating tertinggi oleh pengguna, menggunakan model Nearest Neighbors untuk memberikan rekomendasi, lalu menghilangkan duplikasi dari daftar rekomendasi akhir."
      ],
      "metadata": {
        "id": "IKSqxC-46z0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_for_user(user_id, ratings_books, n_recommendations=10):\n",
        "    user_ratings = ratings_books[ratings_books['User-ID'] == user_id]\n",
        "\n",
        "    if user_ratings.empty:\n",
        "        return \"Pengguna tidak ditemukan atau belum memberikan rating.\"\n",
        "\n",
        "    top_rated_books = user_ratings.sort_values(by='Book-Rating', ascending=False).head(5)\n",
        "\n",
        "    recommended_books = []\n",
        "    for book in top_rated_books['Book-Title'].values:\n",
        "        recommended_books.extend(get_nn_recommendations(book, n_recommendations))\n",
        "\n",
        "    recommended_books = list(dict.fromkeys(recommended_books))\n",
        "\n",
        "    return recommended_books[:n_recommendations]"
      ],
      "metadata": {
        "id": "w1MKQIhprA3_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mendefinisikan fungsi interactive_recommendation untuk menjalankan rekomendasi secara interaktif. Jika input berupa ID pengguna (digit), rekomendasi diberikan berdasarkan preferensi pengguna tersebut. Jika input berupa judul buku (teks), rekomendasi diberikan berdasarkan judul buku dengan bantuan fuzzy matching. Fungsi ini dijalankan dua kali untuk menguji interaktivitas."
      ],
      "metadata": {
        "id": "w1mSw4Zt64SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_recommendation():\n",
        "    user_input = input(\"Masukkan judul buku atau ID pengguna: \")\n",
        "\n",
        "    if user_input.isdigit():\n",
        "        user_id = int(user_input)\n",
        "        print(f\"Rekomendasi untuk pengguna {user_id}:\")\n",
        "        print(recommend_for_user(user_id, ratings_books))\n",
        "    else:\n",
        "        print(f\"Rekomendasi untuk buku '{user_input}':\")\n",
        "        print(get_fuzzy_nn_recommendations(user_input))\n",
        "\n",
        "interactive_recommendation()\n",
        "interactive_recommendation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQhfqEh6p4FV",
        "outputId": "9d8cc399-03d2-4d78-9bad-6d7ba3279b4e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masukkan judul buku atau ID pengguna: The Joy Luck Club\n",
            "Rekomendasi untuk buku 'The Joy Luck Club':\n",
            "Menampilkan rekomendasi untuk: 'The Joy Luck Club'\n",
            "42378                              The Joy Luck Club\n",
            "41356                                  Joy Luck Club\n",
            "32773                              The Joy Luck Club\n",
            "211474                            Joy Luck Club-O.M.\n",
            "13759     The Joy Luck Club (Vintage Contemporaries)\n",
            "207429                               Beginner's Luck\n",
            "151326                                 The Moon Lady\n",
            "82694                      The Hundred Secret Senses\n",
            "10715                      The Hundred Secret Senses\n",
            "54623                      The Hundred Secret Senses\n",
            "Name: Book-Title, dtype: object\n",
            "Masukkan judul buku atau ID pengguna: 276798\n",
            "Rekomendasi untuk pengguna 276798:\n",
            "['Ein Mord fÃ?Â¼r Kay Scarpetta', 'Ein Fall fÃ?Â¼r Kay Scarpetta.', 'Brandherd 5 CDs. Ein Fall fÃ?Â¼r Kay Scarpetta.', 'Blinder Passagier. Ein neuer Fall fÃ?Â¼r Kay Scarpetta.', 'Blinder Passagier. Ein Kay- Scarpetta- Roman.', 'All That Remains (Kay Scarpetta Mysteries (Paperback))', 'Postmortem (Kay Scarpetta Mysteries (Paperback))', 'Body of Evidence (Kay Scarpetta Mysteries (Paperback))', 'Trace (Kay Scarpetta Mysteries (Hardcover))', 'POSTMORTEM (Kay Scarpetta Mysteries (Hardcover))']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "Nyfl3ULP81eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membagi dataset penilaian menjadi data latih (80%) dan data uji (20%) menggunakan train_test_split. Menampilkan ukuran data latih dan data uji untuk memverifikasi pembagian."
      ],
      "metadata": {
        "id": "tYTgv9pS7KzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(ratings_clean, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Train data size: {train_data.shape}\")\n",
        "print(f\"Test data size: {test_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v9zK4tVrWfX",
        "outputId": "077fa06e-e230-4d37-863a-49688a7b8d5d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data size: (919824, 3)\n",
            "Test data size: (229956, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mendefinisikan fungsi evaluate_recommendations untuk mengevaluasi rekomendasi yang diberikan kepada seorang pengguna berdasarkan precision, recall, dan F1-score. Fungsi ini memeriksa buku yang diberi rating tinggi (>= 8) oleh pengguna sebagai 'true positives', lalu membandingkannya dengan buku yang direkomendasikan. Metrik precision, recall, dan F1 dihitung untuk menilai akurasi rekomendasi."
      ],
      "metadata": {
        "id": "3sBg7nsj7N-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_recommendations(user_id, model_nn, n_recommendations=10):\n",
        "    user_test_ratings = test_data[test_data['User-ID'] == user_id]\n",
        "\n",
        "    if user_test_ratings.empty:\n",
        "        return None\n",
        "\n",
        "    true_positive_books = user_test_ratings[user_test_ratings['Book-Rating'] >= 8]['ISBN'].values\n",
        "\n",
        "    recommended_books = recommend_for_user(user_id, ratings_books, n_recommendations)\n",
        "\n",
        "    if not recommended_books:\n",
        "        return None\n",
        "\n",
        "    if isinstance(recommended_books, str):\n",
        "        recommended_books = [recommended_books]\n",
        "\n",
        "    recommended_books_isbn = books_clean[books_clean['Book-Title'].isin(recommended_books)]['ISBN'].values\n",
        "\n",
        "    y_true = [1 if isbn in true_positive_books else 0 for isbn in recommended_books_isbn]\n",
        "    y_pred = [1] * len(recommended_books_isbn)\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "metadata": {
        "id": "DkOTfW4Qv5_z"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mendefinisikan fungsi evaluate_for_sampled_users_in_batch yang mengevaluasi rekomendasi untuk sekelompok pengguna secara batch. Fungsi ini menghitung precision, recall, dan F1-score rata-rata untuk pengguna yang diambil secara acak dari data uji. Evaluasi dilakukan secara batch untuk efisiensi. Hasil akhirnya adalah precision, recall, dan F1-score rata-rata untuk semua pengguna yang diuji."
      ],
      "metadata": {
        "id": "kCCEWnXS7UXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_user_ids = np.random.choice(test_data['User-ID'].unique(), size=int(0.1 * len(test_data['User-ID'].unique())), replace=False)\n",
        "\n",
        "def evaluate_for_sampled_users_in_batch(test_data, model_nn, sampled_user_ids, batch_size=100, n_recommendations=10):\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for i in range(0, len(sampled_user_ids), batch_size):\n",
        "        batch_user_ids = sampled_user_ids[i:i + batch_size]\n",
        "        for user_id in batch_user_ids:\n",
        "            result = evaluate_recommendations(user_id, model_nn, n_recommendations)\n",
        "            if result:\n",
        "                precision, recall, f1 = result\n",
        "                precisions.append(precision)\n",
        "                recalls.append(recall)\n",
        "                f1_scores.append(f1)\n",
        "\n",
        "    avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "    avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "    avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
        "\n",
        "    return avg_precision, avg_recall, avg_f1\n",
        "\n",
        "avg_precision, avg_recall, avg_f1 = evaluate_for_sampled_users_in_batch(test_data, model_nn, sampled_user_ids, batch_size=100)\n",
        "\n",
        "print(f\"Rata-rata Precision: {avg_precision}\")\n",
        "print(f\"Rata-rata Recall: {avg_recall}\")\n",
        "print(f\"Rata-rata F1-score: {avg_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgsWe6BXnQMc",
        "outputId": "acbe0ca0-8892-4951-bd6b-3da672e1e58a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rata-rata Precision: 0.08172273640849355\n",
            "Rata-rata Recall: 1.0\n",
            "Rata-rata F1-score: 0.08844182146442586\n"
          ]
        }
      ]
    }
  ]
}